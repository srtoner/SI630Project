{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import TwitterUtils as TU\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import spacy_langdetect as sld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tweepy\n",
    "import time\n",
    "\n",
    "with open('my_oauth.json', 'r') as f:\n",
    "    oauth_tokens = json.load(f)\n",
    "\n",
    "\n",
    "consumer_key = os.environ.get(\"CONSUMER_KEY\")\n",
    "consumer_secret = os.environ.get(\"CONSUMER_SECRET\")\n",
    "access_token = oauth_tokens['oauth_token']\n",
    "access_token_secret = oauth_tokens['oauth_token_secret']\n",
    "\n",
    "# tweepy workflow, not sure how it differs from twint\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data\n",
    "\n",
    "The `GetPlaces.py`, `GetTweets.py`, and `SampleUser.py` files have generated the following output files:\n",
    "* users.json : contains all the user specific data from the 51,000 sampled users\n",
    "* places.pkl : metadata related to all twitter places in the user sample\n",
    "* tweets.pkl : retrieved 100 tweets from each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_regex = 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&\\/\\/=]*)'\n",
    "twitter_username_re = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)'\n",
    "twitter_username_re = r\"((^|[^@\\w])@(\\w{1,15})\\b)*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pipeline_data.pkl\", 'rb') as f:\n",
    "    convos = pkl.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_df = pd.DataFrame(convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convo_df.iloc[1000,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(convo_df.tweet_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = convo_df.tweet_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = api.get_status(id_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": [{\"id\": \"1648380717137793025\", \"value\": \"(a OR the) has:geo lang:en tweets_count:50\", \"tag\": \"active_user\"}], \"meta\": {\"sent\": \"2023-04-18T17:50:42.385Z\", \"result_count\": 1}}\n",
      "{\"meta\": {\"sent\": \"2023-04-18T17:50:42.676Z\", \"summary\": {\"deleted\": 1, \"not_deleted\": 0}}}\n",
      "{\"data\": [{\"value\": \"(a OR the) has:geo lang:en tweets_count:50\", \"tag\": \"active_user\", \"id\": \"1648383568819916801\"}], \"meta\": {\"sent\": \"2023-04-18T17:50:42.970Z\", \"summary\": {\"created\": 1, \"not_created\": 0, \"valid\": 1, \"invalid\": 0}}}\n"
     ]
    }
   ],
   "source": [
    "client = TU.TwitterClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196902"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_url = TU.BASE + 'tweets/'\n",
    "kernel_params = {'tweet.fields' : 'author_id,conversation_id,created_at,in_reply_to_user_id,referenced_tweets'}\n",
    "kernel_params['ids'] = \",\".join(id_list)\n",
    "\n",
    "output = client.connect_to_endpoint(kernel_url, kernel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n",
      "429\n"
     ]
    }
   ],
   "source": [
    "timestamps = []\n",
    "\n",
    "for id_ in id_list[::100]:\n",
    "    kernel_params['ids'] = \",\".join(id_)\n",
    "   \n",
    "    try:\n",
    "        output = client.connect_to_endpoint(kernel_url, kernel_params)\n",
    "        timestamps.append(output)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m timestamps\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timestamps' is not defined"
     ]
    }
   ],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "(431, 'Request Header Fields Too Large')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m kernel_params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtweet.fields\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mauthor_id,conversation_id,created_at,in_reply_to_user_id,referenced_tweets\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m      3\u001b[0m kernel_params[\u001b[39m'\u001b[39m\u001b[39mids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(id_list)\n\u001b[0;32m----> 5\u001b[0m output \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mconnect_to_endpoint(kernel_url, kernel_params)\n",
      "File \u001b[0;32m~/Desktop/Winter 2023/SI 630/SI630Project/TwitterUtils.py:120\u001b[0m, in \u001b[0;36mTwitterClient.connect_to_endpoint\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39mstatus_code)\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    121\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mException\u001b[0m: (431, 'Request Header Fields Too Large')"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/2/users/{}/tweets\".format(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.4085"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*196902 / 100 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1638630321473335297': datetime.datetime(2023, 3, 22, 19, 54, 47, tzinfo=datetime.timezone.utc),\n",
       " '1638112643293511681': datetime.datetime(2023, 3, 21, 9, 37, 43, tzinfo=datetime.timezone.utc),\n",
       " '1638034126531104768': datetime.datetime(2023, 3, 21, 4, 25, 43, tzinfo=datetime.timezone.utc),\n",
       " '1638031325126074369': datetime.datetime(2023, 3, 21, 4, 14, 35, tzinfo=datetime.timezone.utc),\n",
       " '1638027677776113670': datetime.datetime(2023, 3, 21, 4, 0, 6, tzinfo=datetime.timezone.utc),\n",
       " '1638023870933344256': datetime.datetime(2023, 3, 21, 3, 44, 58, tzinfo=datetime.timezone.utc),\n",
       " '1638018184262606849': datetime.datetime(2023, 3, 21, 3, 22, 22, tzinfo=datetime.timezone.utc),\n",
       " '1638003069635153921': datetime.datetime(2023, 3, 21, 2, 22, 19, tzinfo=datetime.timezone.utc),\n",
       " '1640039436976287744': datetime.datetime(2023, 3, 26, 17, 14, 6, tzinfo=datetime.timezone.utc),\n",
       " '1639832760180428800': datetime.datetime(2023, 3, 26, 3, 32, 51, tzinfo=datetime.timezone.utc),\n",
       " '1639420281147080708': datetime.datetime(2023, 3, 25, 0, 13, 48, tzinfo=datetime.timezone.utc),\n",
       " '1639418704185139202': datetime.datetime(2023, 3, 25, 0, 7, 32, tzinfo=datetime.timezone.utc),\n",
       " '1639283766001532928': datetime.datetime(2023, 3, 24, 15, 11, 20, tzinfo=datetime.timezone.utc),\n",
       " '1639282456846114816': datetime.datetime(2023, 3, 24, 15, 6, 8, tzinfo=datetime.timezone.utc),\n",
       " '1638858997402058753': datetime.datetime(2023, 3, 23, 11, 3, 28, tzinfo=datetime.timezone.utc),\n",
       " '1638848416762703872': datetime.datetime(2023, 3, 23, 10, 21, 25, tzinfo=datetime.timezone.utc),\n",
       " '1638815869743824898': datetime.datetime(2023, 3, 23, 8, 12, 5, tzinfo=datetime.timezone.utc),\n",
       " '1638708493996941314': datetime.datetime(2023, 3, 23, 1, 5, 25, tzinfo=datetime.timezone.utc),\n",
       " '1637292033584033792': datetime.datetime(2023, 3, 19, 3, 16, 54, tzinfo=datetime.timezone.utc),\n",
       " '1637291464626679808': datetime.datetime(2023, 3, 19, 3, 14, 39, tzinfo=datetime.timezone.utc),\n",
       " '1636620772021096450': datetime.datetime(2023, 3, 17, 6, 49, 33, tzinfo=datetime.timezone.utc),\n",
       " '1636616768092516352': datetime.datetime(2023, 3, 17, 6, 33, 39, tzinfo=datetime.timezone.utc),\n",
       " '1636593371123978240': datetime.datetime(2023, 3, 17, 5, 0, 40, tzinfo=datetime.timezone.utc),\n",
       " '1636570052752457728': datetime.datetime(2023, 3, 17, 3, 28, 1, tzinfo=datetime.timezone.utc),\n",
       " '1636568248509665282': datetime.datetime(2023, 3, 17, 3, 20, 51, tzinfo=datetime.timezone.utc),\n",
       " '1636567213787480067': datetime.datetime(2023, 3, 17, 3, 16, 44, tzinfo=datetime.timezone.utc),\n",
       " '1636561629277044738': datetime.datetime(2023, 3, 17, 2, 54, 32, tzinfo=datetime.timezone.utc),\n",
       " '1636557447627444226': datetime.datetime(2023, 3, 17, 2, 37, 55, tzinfo=datetime.timezone.utc),\n",
       " '1637428071492886531': datetime.datetime(2023, 3, 19, 12, 17, 28, tzinfo=datetime.timezone.utc),\n",
       " '1637334843997687809': datetime.datetime(2023, 3, 19, 6, 7, 1, tzinfo=datetime.timezone.utc),\n",
       " '1637290149318119424': datetime.datetime(2023, 3, 19, 3, 9, 25, tzinfo=datetime.timezone.utc),\n",
       " '1637284891569328128': datetime.datetime(2023, 3, 19, 2, 48, 32, tzinfo=datetime.timezone.utc),\n",
       " '1637119964477014021': datetime.datetime(2023, 3, 18, 15, 53, 10, tzinfo=datetime.timezone.utc),\n",
       " '1637119932822609921': datetime.datetime(2023, 3, 18, 15, 53, 2, tzinfo=datetime.timezone.utc),\n",
       " '1637072344043896835': datetime.datetime(2023, 3, 18, 12, 43, 56, tzinfo=datetime.timezone.utc),\n",
       " '1637061002662649859': datetime.datetime(2023, 3, 18, 11, 58, 52, tzinfo=datetime.timezone.utc),\n",
       " '1636997687425007616': datetime.datetime(2023, 3, 18, 7, 47, 17, tzinfo=datetime.timezone.utc),\n",
       " '1636923517852856321': datetime.datetime(2023, 3, 18, 2, 52, 33, tzinfo=datetime.timezone.utc),\n",
       " '1636794470829273088': datetime.datetime(2023, 3, 17, 18, 19, 46, tzinfo=datetime.timezone.utc),\n",
       " '1636753473629741056': datetime.datetime(2023, 3, 17, 15, 36, 52, tzinfo=datetime.timezone.utc),\n",
       " '1636645108237078528': datetime.datetime(2023, 3, 17, 8, 26, 15, tzinfo=datetime.timezone.utc),\n",
       " '1636599880138514432': datetime.datetime(2023, 3, 17, 5, 26, 32, tzinfo=datetime.timezone.utc),\n",
       " '1636592187319234561': datetime.datetime(2023, 3, 17, 4, 55, 58, tzinfo=datetime.timezone.utc),\n",
       " '1636570938300047361': datetime.datetime(2023, 3, 17, 3, 31, 32, tzinfo=datetime.timezone.utc),\n",
       " '1636570176278917121': datetime.datetime(2023, 3, 17, 3, 28, 30, tzinfo=datetime.timezone.utc),\n",
       " '1636438018067423232': datetime.datetime(2023, 3, 16, 18, 43, 21, tzinfo=datetime.timezone.utc),\n",
       " '1636599992503640064': datetime.datetime(2023, 3, 17, 5, 26, 59, tzinfo=datetime.timezone.utc),\n",
       " '1637434782509576192': datetime.datetime(2023, 3, 19, 12, 44, 8, tzinfo=datetime.timezone.utc),\n",
       " '1637141140582301696': datetime.datetime(2023, 3, 18, 17, 17, 19, tzinfo=datetime.timezone.utc),\n",
       " '1637017429569318912': datetime.datetime(2023, 3, 18, 9, 5, 44, tzinfo=datetime.timezone.utc),\n",
       " '1636980579534254080': datetime.datetime(2023, 3, 18, 6, 39, 18, tzinfo=datetime.timezone.utc),\n",
       " '1636943421301723136': datetime.datetime(2023, 3, 18, 4, 11, 39, tzinfo=datetime.timezone.utc),\n",
       " '1636942204458479616': datetime.datetime(2023, 3, 18, 4, 6, 49, tzinfo=datetime.timezone.utc),\n",
       " '1636888627337904129': datetime.datetime(2023, 3, 18, 0, 33, 55, tzinfo=datetime.timezone.utc),\n",
       " '1636823231104466944': datetime.datetime(2023, 3, 17, 20, 14, 3, tzinfo=datetime.timezone.utc),\n",
       " '1636801233598939156': datetime.datetime(2023, 3, 17, 18, 46, 39, tzinfo=datetime.timezone.utc),\n",
       " '1636795528280428546': datetime.datetime(2023, 3, 17, 18, 23, 58, tzinfo=datetime.timezone.utc),\n",
       " '1636624667095236609': datetime.datetime(2023, 3, 17, 7, 5, 2, tzinfo=datetime.timezone.utc),\n",
       " '1636624424916119552': datetime.datetime(2023, 3, 17, 7, 4, 4, tzinfo=datetime.timezone.utc),\n",
       " '1636566142620925956': datetime.datetime(2023, 3, 17, 3, 12, 28, tzinfo=datetime.timezone.utc),\n",
       " '1636538889392525312': datetime.datetime(2023, 3, 17, 1, 24, 11, tzinfo=datetime.timezone.utc),\n",
       " '1636685957658189825': datetime.datetime(2023, 3, 17, 11, 8, 35, tzinfo=datetime.timezone.utc),\n",
       " '1636466937642491905': datetime.datetime(2023, 3, 16, 20, 38, 16, tzinfo=datetime.timezone.utc),\n",
       " '1636437329492713472': datetime.datetime(2023, 3, 16, 18, 40, 37, tzinfo=datetime.timezone.utc),\n",
       " '1636449082880425984': datetime.datetime(2023, 3, 16, 19, 27, 19, tzinfo=datetime.timezone.utc),\n",
       " '1636428515456299008': datetime.datetime(2023, 3, 16, 18, 5, 36, tzinfo=datetime.timezone.utc),\n",
       " '1636612650321707010': datetime.datetime(2023, 3, 17, 6, 17, 17, tzinfo=datetime.timezone.utc),\n",
       " '1636477502658064384': datetime.datetime(2023, 3, 16, 21, 20, 15, tzinfo=datetime.timezone.utc),\n",
       " '1636437421910020096': datetime.datetime(2023, 3, 16, 18, 40, 59, tzinfo=datetime.timezone.utc),\n",
       " '1636434774624706561': datetime.datetime(2023, 3, 16, 18, 30, 28, tzinfo=datetime.timezone.utc),\n",
       " '1636431855334612992': datetime.datetime(2023, 3, 16, 18, 18, 52, tzinfo=datetime.timezone.utc),\n",
       " '1636430576583409669': datetime.datetime(2023, 3, 16, 18, 13, 47, tzinfo=datetime.timezone.utc),\n",
       " '1636417141640683520': datetime.datetime(2023, 3, 16, 17, 20, 24, tzinfo=datetime.timezone.utc),\n",
       " '1636413026026000385': datetime.datetime(2023, 3, 16, 17, 4, 3, tzinfo=datetime.timezone.utc),\n",
       " '1636408246201376768': datetime.datetime(2023, 3, 16, 16, 45, 3, tzinfo=datetime.timezone.utc),\n",
       " '1636406886395428865': datetime.datetime(2023, 3, 16, 16, 39, 39, tzinfo=datetime.timezone.utc),\n",
       " '1636405015240929281': datetime.datetime(2023, 3, 16, 16, 32, 13, tzinfo=datetime.timezone.utc),\n",
       " '1636431412562886656': datetime.datetime(2023, 3, 16, 18, 17, 6, tzinfo=datetime.timezone.utc),\n",
       " '1636676525855473664': datetime.datetime(2023, 3, 17, 10, 31, 6, tzinfo=datetime.timezone.utc),\n",
       " '1636618105286950915': datetime.datetime(2023, 3, 17, 6, 38, 57, tzinfo=datetime.timezone.utc),\n",
       " '1636354136538218497': datetime.datetime(2023, 3, 16, 13, 10, 2, tzinfo=datetime.timezone.utc),\n",
       " '1636292495771586560': datetime.datetime(2023, 3, 16, 9, 5, 6, tzinfo=datetime.timezone.utc),\n",
       " '1636292246973853699': datetime.datetime(2023, 3, 16, 9, 4, 7, tzinfo=datetime.timezone.utc),\n",
       " '1636279300461858816': datetime.datetime(2023, 3, 16, 8, 12, 40, tzinfo=datetime.timezone.utc),\n",
       " '1636381798942003201': datetime.datetime(2023, 3, 16, 14, 59, 58, tzinfo=datetime.timezone.utc),\n",
       " '1636258749886390272': datetime.datetime(2023, 3, 16, 6, 51, tzinfo=datetime.timezone.utc),\n",
       " '1636257525275435008': datetime.datetime(2023, 3, 16, 6, 46, 8, tzinfo=datetime.timezone.utc),\n",
       " '1636257132533383168': datetime.datetime(2023, 3, 16, 6, 44, 35, tzinfo=datetime.timezone.utc),\n",
       " '1636384106295721989': datetime.datetime(2023, 3, 16, 15, 9, 8, tzinfo=datetime.timezone.utc),\n",
       " '1636382325427822593': datetime.datetime(2023, 3, 16, 15, 2, 3, tzinfo=datetime.timezone.utc),\n",
       " '1636322963485241350': datetime.datetime(2023, 3, 16, 11, 6, 10, tzinfo=datetime.timezone.utc),\n",
       " '1636213706936963072': datetime.datetime(2023, 3, 16, 3, 52, 1, tzinfo=datetime.timezone.utc),\n",
       " '1636213098368442373': datetime.datetime(2023, 3, 16, 3, 49, 36, tzinfo=datetime.timezone.utc),\n",
       " '1636210979431419906': datetime.datetime(2023, 3, 16, 3, 41, 11, tzinfo=datetime.timezone.utc),\n",
       " '1636206240589127680': datetime.datetime(2023, 3, 16, 3, 22, 21, tzinfo=datetime.timezone.utc),\n",
       " '1636204225175879681': datetime.datetime(2023, 3, 16, 3, 14, 21, tzinfo=datetime.timezone.utc),\n",
       " '1636184917577986048': datetime.datetime(2023, 3, 16, 1, 57, 37, tzinfo=datetime.timezone.utc),\n",
       " '1636183759291809792': datetime.datetime(2023, 3, 16, 1, 53, 1, tzinfo=datetime.timezone.utc),\n",
       " '1636330078446702592': datetime.datetime(2023, 3, 16, 11, 34, 26, tzinfo=datetime.timezone.utc)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '1013303513449836547',\n",
       " 'tweet_id': '1638630321473335297',\n",
       " 'tweet_text': '@1shankarsharma @Pavanasoonu Think.... astrologers are more accurate than market pundits.',\n",
       " 'referenced_tweets': [{'type': 'replied_to', 'id': '1637748357127864320'}],\n",
       " 'convo_id': '1637733079002537986',\n",
       " 'reply_to_user_id': '2989553946'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_dict = {}\n",
    "\n",
    "for c in convos:\n",
    "    if convo_dict.get(c['convo_id']):\n",
    "        convo_dict[c['convo_id']].append(c)\n",
    "    else:\n",
    "        convo_dict[c['convo_id']] = [c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "replied_to_list = [c['referenced_tweets'][-1].get('id') for c in convos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_df['referenced_tweets'] = replied_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = convo_df.tweet_id.apply(str)\n",
    "referenced_tweets = convo_df.referenced_tweets.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/vw0sn5w90nnccbfn7bskv0jm0000gn/T/ipykernel_8359/3908887897.py:1: DtypeWarning: Columns (0,1,10,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  og_data = pd.read_csv('filtered_data.csv')\n"
     ]
    }
   ],
   "source": [
    "og_data = pd.read_csv('filtered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_data['tweet_id'].dtype\n",
    "convo_df['tweet_id'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_tweet_ids = og_data.tweet_id.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1637850668214960128\n",
       "1         1637818231863001090\n",
       "2         1637737394911969280\n",
       "3         1637733079002537986\n",
       "4         1637660117624836096\n",
       "                 ...         \n",
       "944493    1637686649470730240\n",
       "944494    1637307250380505093\n",
       "944495    1637299644664549381\n",
       "944496    1637040000335495170\n",
       "944497    1636604644813328385\n",
       "Name: tweet_id, Length: 944498, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([ref in og_tweet_ids for ref in referenced_tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_convo = convo_df[convo_df['convo_id'] == convo_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1637748357127864320\n",
       "1         1637749653906272256\n",
       "2         1637733079002537986\n",
       "3         1637748357127864320\n",
       "4         1638023870933344256\n",
       "                 ...         \n",
       "641677    1637748357127864320\n",
       "641678    1638023870933344256\n",
       "641679    1637850668214960128\n",
       "641680    1637748357127864320\n",
       "641681    1637748357127864320\n",
       "Name: referenced_tweets, Length: 120, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_convo.referenced_tweets.apply(lambda x: x[0].get('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = filtered_convo.tweet_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1638630321473335297', '1638112643293511681',\n",
       "       '1638034126531104768', '1638031325126074369',\n",
       "       '1638027677776113670', '1638023870933344256',\n",
       "       '1638018184262606849', '1638003069635153921'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_unpacked = [item  for item in places.values()]\n",
    "def unpack_place(place):\n",
    "    return (place.id, place.name, place.full_name, place.country, place.country_code, place.place_type)\n",
    "\n",
    "unpacked_places = [unpack_place(place) for place in places_unpacked]\n",
    "place_df = pd.DataFrame(unpacked_places, columns = (\"id\", \"name\", \"full_name\", \"country\", \"country_code\", \"type\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL_regex = 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_regex = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&\\/\\/=]*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "merged = pd.merge(df, place_df, how = 'left', left_on = 'place_id', right_on='id')\n",
    "full_data = pd.merge(merged, users_df, how='left', left_on ='user_id', right_on = 'id')\n",
    "# full_data.to_csv('fulldata.csv', index = False) # 3 Gigs of data, not great...\n",
    "# full_data.description.iloc[0,]\n",
    "# places_unpacked # Cool opportunity for geographic visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30470"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066735266648764"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit to top 6 countries\n",
    "by_country = merged.groupby('country').count()\n",
    "top6 = by_country.sort_values(by = 'user_id', ascending=False).head(6)\n",
    "total = by_country.user_id.sum()\n",
    "top6.user_id.divide(total).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'tweet_id', 'tweet_text', 'place_id', 'id_x', 'name',\n",
       "       'full_name', 'country', 'country_code', 'type', 'username',\n",
       "       'description', 'id_y', 'user_name_field', 'location', 'withheld'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 6 countries account for 91% of the total users collected, which suggests pretty good coverage. Dropping unnecessary columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fields = ['user_id', 'tweet_id', 'tweet_text', 'place_id', 'name',\n",
    "       'full_name', 'country', 'country_code', 'type', 'username',\n",
    "       'description', 'user_name_field', 'location']\n",
    "reduced_df = full_data[target_fields]\n",
    "reduced_df = reduced_df.rename(columns={'name':'place_name', \n",
    "                                        'full_name':'full_place_name',\n",
    "                                        'type': 'place_type', \n",
    "                                        'description':'profile_description',\n",
    "                                        'user_name_field':'profile_name',\n",
    "                                        'location':'profile_location'\n",
    "                                        })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "top6_countries = top6.index\n",
    "top6 = reduced_df[reduced_df['country'].isin(top6_countries)]\n",
    "unique_tweets = top6['tweet_id'].unique()\n",
    "top6 = top6.drop_duplicates('tweet_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_detector(nlp, name):\n",
    "    return sld.LanguageDetector()\n",
    "\n",
    "# Uncomment when running for first time\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy.Language.factory('language_detector', func = get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last =True)\n",
    "\n",
    "def get_language(text):\n",
    "    return nlp(text)._.language['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999960942533268"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_language(top6.tweet_text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = top6.to_dict(orient='records')\n",
    "langs = [get_language(d['tweet_text']) for d in data_dict]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Tweet Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Gajendr70729189 @amitsharma2704 @1shankarsharma Including my SAP technology business.  Thank you. Namaste.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = top6.tweet_text.iloc[1]\n",
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Including my SAP technology business.  Thank you. Namaste.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(URL_regex, \"\", text_test)\n",
    "re.sub(twitter_username_re, \"\", text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    temp = re.sub(URL_regex, \"\", text)\n",
    "\n",
    "    return re.sub(twitter_username_re, \"\", text)\n",
    "\n",
    "top6['clean_text'] = top6.tweet_text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859183, 14)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top6 = top6.drop_duplicates('tweet_id')\n",
    "top6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top6.to_csv('filtered_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
