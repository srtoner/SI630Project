{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import TwitterUtils as TU\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "import spacy_langdetect as sld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data\n",
    "\n",
    "The `GetPlaces.py`, `GetTweets.py`, and `SampleUser.py` files have generated the following output files:\n",
    "* users.json : contains all the user specific data from the 51,000 sampled users\n",
    "* places.pkl : metadata related to all twitter places in the user sample\n",
    "* user_data.pkl : retrieved 100 tweets from each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_regex = 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&\\/\\/=]*)'\n",
    "twitter_username_re = '(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)'\n",
    "twitter_username_re = r\"((^|[^@\\w])@(\\w{1,15})\\b)*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"places.pkl\", \"rb\") as file: # Unique Places\n",
    "    places = pkl.load(file)\n",
    "\n",
    "with open('user_data.pkl', 'rb') as file: # Rename to Tweets, user_id, place_id\n",
    "    data = pkl.load(file)\n",
    "\n",
    "with open('users.json', 'r') as file: # Actual data for user accounts\n",
    "    user_json = file.read()\n",
    "\n",
    "test = '{\"total\": [' + user_json.replace(\"}{\", \"},{\") + \"]}\"\n",
    "user_data = json.loads(test)\n",
    "users = [u['data'] for u in user_data[\"total\"]]\n",
    "flat_list = [user_id for user in users for user_id in user]\n",
    "\n",
    "users_df = pd.DataFrame(flat_list).rename(columns = {'name' : 'user_name_field'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "places_unpacked = [item  for item in places.values()]\n",
    "def unpack_place(place):\n",
    "    return (place.id, place.name, place.full_name, place.country, place.country_code, place.place_type)\n",
    "\n",
    "unpacked_places = [unpack_place(place) for place in places_unpacked]\n",
    "place_df = pd.DataFrame(unpacked_places, columns = (\"id\", \"name\", \"full_name\", \"country\", \"country_code\", \"type\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL_regex = 'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_regex = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&\\/\\/=]*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "merged = pd.merge(df, place_df, how = 'left', left_on = 'place_id', right_on='id')\n",
    "full_data = pd.merge(merged, users_df, how='left', left_on ='user_id', right_on = 'id')\n",
    "# full_data.to_csv('fulldata.csv', index = False) # 3 Gigs of data, not great...\n",
    "# full_data.description.iloc[0,]\n",
    "# places_unpacked # Cool opportunity for geographic visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066735266648764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limit to top 6 countries\n",
    "by_country = merged.groupby('country').count()\n",
    "top6 = by_country.sort_values(by = 'user_id', ascending=False).head(6)\n",
    "total = by_country.user_id.sum()\n",
    "top6.user_id.divide(total).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 6 countries account for 91% of the total users collected, which suggests pretty good coverage. Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fields = ['user_id', 'tweet_id', 'tweet_text', 'place_id', 'name',\n",
    "       'full_name', 'country', 'country_code', 'type', 'username',\n",
    "       'description', 'user_name_field', 'location', 'withheld']\n",
    "reduced_df = full_data[target_fields]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top6_countries = top6.index\n",
    "top6 = reduced_df[reduced_df['country'].isin(top6_countries)]\n",
    "unique_tweets = top6['tweet_id'].unique()\n",
    "top6 = top6.drop_duplicates('tweet_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang_detector(nlp, name):\n",
    "    return sld.LanguageDetector()\n",
    "\n",
    "# Uncomment when running for first time\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy.Language.factory('language_detector', func = get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last =True)\n",
    "\n",
    "def get_language(text):\n",
    "    return nlp(text)._.language['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_dict \u001b[39m=\u001b[39m top6\u001b[39m.\u001b[39mto_dict(orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m langs \u001b[39m=\u001b[39m [get_language(d[\u001b[39m'\u001b[39m\u001b[39mtweet_text\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data_dict]\n",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m data_dict \u001b[39m=\u001b[39m top6\u001b[39m.\u001b[39mto_dict(orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m langs \u001b[39m=\u001b[39m [get_language(d[\u001b[39m'\u001b[39;49m\u001b[39mtweet_text\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data_dict]\n",
      "Cell \u001b[0;32mIn[33], line 10\u001b[0m, in \u001b[0;36mget_language\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_language\u001b[39m(text):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m nlp(text)\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mlanguage[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/spacy/language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx:274\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    312\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/spacy/ml/tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[0;32m---> 33\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[1;32m     34\u001b[0m         X,\n\u001b[1;32m     35\u001b[0m         model\u001b[39m.\u001b[39;49mlayers,\n\u001b[1;32m     36\u001b[0m         unseen_classes\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39munseen_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     37\u001b[0m         train\u001b[39m=\u001b[39;49mis_train,\n\u001b[1;32m     38\u001b[0m         has_upper\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mhas_upper\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/spacy/ml/parser_model.pyx:213\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/layers/with_array.py:38\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m](Xseq, is_train)\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/layers/with_array.py:80\u001b[0m, in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     77\u001b[0m     dXf \u001b[39m=\u001b[39m get_dXf(dYf)\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m layer\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39munflatten(dXf, lengths, pad\u001b[39m=\u001b[39mpad)\n\u001b[0;32m---> 80\u001b[0m \u001b[39mreturn\u001b[39;00m layer\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49munflatten(Yf, lengths, pad\u001b[39m=\u001b[39;49mpad), backprop\n",
      "File \u001b[0;32m~/mambaforge/envs/tf_macos/lib/python3.8/site-packages/thinc/backends/ops.py:342\u001b[0m, in \u001b[0;36mOps.unflatten\u001b[0;34m(self, X, lengths, pad)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m pad \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    340\u001b[0m     unflat \u001b[39m=\u001b[39m [a[pad:] \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m unflat]\n\u001b[0;32m--> 342\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(unflat) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39;49m(lengths)\n\u001b[1;32m    344\u001b[0m \u001b[39mreturn\u001b[39;00m unflat\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dict = top6.to_dict(orient='records')\n",
    "langs = [get_language(d['tweet_text']) for d in data_dict]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Tweet Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Gajendr70729189 @amitsharma2704 @1shankarsharma Including my SAP technology business.  Thank you. Namaste.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test = top6.tweet_text.iloc[1]\n",
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Including my SAP technology business.  Thank you. Namaste.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(URL_regex, \"\", text_test)\n",
    "re.sub(twitter_username_re, \"\", text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/vw0sn5w90nnccbfn7bskv0jm0000gn/T/ipykernel_2099/1597261052.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top6['clean_text'] = top6.tweet_text.apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    temp = re.sub(URL_regex, \"\", text)\n",
    "\n",
    "    return re.sub(twitter_username_re, \"\", text)\n",
    "\n",
    "top6['clean_text'] = top6.tweet_text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859183, 15)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top6 = top6.drop_duplicates('tweet_id')\n",
    "\n",
    "top6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "top6.to_csv('filtered_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
