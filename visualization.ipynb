{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b0e84333",
   "metadata": {
    "id": "pujJkh_q8qTi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerConductance, LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "31ad6302",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOkFdQoT8w8X",
    "outputId": "aaf80ccc-4f67-4342-f2f1-ba46f3cb2d19"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"mps:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "afe27727",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/stephentoner/.cache/huggingface/datasets/csv/default-2db754ff7953f4a8/0.0.0)\n",
      "Found cached dataset csv (/Users/stephentoner/.cache/huggingface/datasets/csv/default-c1d4626ff04165b1/0.0.0)\n",
      "Found cached dataset csv (/Users/stephentoner/.cache/huggingface/datasets/csv/default-7083c7f65e06db68/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "ds_train = Dataset.from_csv('train_twitter.csv')\n",
    "ds_val = Dataset.from_csv('validate_twitter.csv')\n",
    "ds_test = Dataset.from_csv('test_twitter.csv')\n",
    "ds_test_viz = ds_test\n",
    "\n",
    "ds = {\"train\": ds_train, \"validation\": ds_val, \"test\": ds_test, \"test_viz\": ds_test_viz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "08c31875",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"United States\", 1: \"United Kingdom\", 2: \"Canada\", 3: \"Australia\", 4: \"India\", 5: \"Nigeria\"}\n",
    "label2id = {\"United States\": 0, \"United Kingdom\": 1, \"Canada\": 2, \"Australia\": 3, \"India\": 4, \"Nigeria\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4fa7876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_id', 'tweet_id', 'tweet_text', 'country'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "11914f7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZptRohBG9CCK",
    "lines_to_next_cell": 2,
    "outputId": "f70a08b8-275d-400e-b85d-b63b06269f03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Twitter/twhin-bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Twitter/twhin-bert-base and are newly initialized: ['bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at /Users/stephentoner/.cache/huggingface/datasets/csv/default-2db754ff7953f4a8/0.0.0/cache-aef5f7b738325a86.arrow\n",
      "Loading cached processed dataset at /Users/stephentoner/.cache/huggingface/datasets/csv/default-c1d4626ff04165b1/0.0.0/cache-6721748a606b7f77.arrow\n",
      "Loading cached processed dataset at /Users/stephentoner/.cache/huggingface/datasets/csv/default-7083c7f65e06db68/0.0.0/cache-b5cda1ebf04b57b0.arrow\n",
      "Loading cached processed dataset at /Users/stephentoner/.cache/huggingface/datasets/csv/default-7083c7f65e06db68/0.0.0/cache-b5cda1ebf04b57b0.arrow\n"
     ]
    }
   ],
   "source": [
    "model_path = 'my_awesome_model'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Twitter/twhin-bert-base\", num_labels=6, id2label=id2label, label2id=label2id)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('Twitter/twhin-bert-base')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    label = examples[\"country\"] \n",
    "    examples = tokenizer(examples[\"tweet_text\"], truncation=True, padding=\"max_length\", max_length=256, return_tensors='pt')\n",
    "    for key in examples:\n",
    "        examples[key] = examples[key].squeeze(0)\n",
    "    examples[\"label\"] = label\n",
    "    return examples\n",
    "\n",
    "for split in ds:\n",
    "    ds[split] = ds[split].map(preprocess_function, remove_columns=['user_id', 'tweet_id', 'tweet_text', 'country'])\n",
    "    ds[split].set_format('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cb494d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test_viz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "64a0aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[198], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ds[\u001b[39m'\u001b[39m\u001b[39mtest_viz\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ds[\u001b[39m'\u001b[39m\u001b[39mtest_viz\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfilter(\u001b[39mlambda\u001b[39;00m ex: ex[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem() \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m ds_test_viz \u001b[39m=\u001b[39m ds_test_viz\u001b[39m.\u001b[39;49mfilter(\u001b[39mlambda\u001b[39;49;00m ex: ex[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mitem() \u001b[39m==\u001b[39;49m \u001b[39m4\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    526\u001b[0m }\n\u001b[1;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/fingerprint.py:511\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    509\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m out \u001b[39m=\u001b[39m func(dataset, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    513\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:3531\u001b[0m, in \u001b[0;36mDataset.filter\u001b[0;34m(self, function, with_indices, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3529\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m-> 3531\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m   3532\u001b[0m     function\u001b[39m=\u001b[39;49mpartial(\n\u001b[1;32m   3533\u001b[0m         get_indices_from_mask_function, function, batched, with_indices, input_columns, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices\n\u001b[1;32m   3534\u001b[0m     ),\n\u001b[1;32m   3535\u001b[0m     with_indices\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3536\u001b[0m     features\u001b[39m=\u001b[39;49mFeatures({\u001b[39m\"\u001b[39;49m\u001b[39mindices\u001b[39;49m\u001b[39m\"\u001b[39;49m: Value(\u001b[39m\"\u001b[39;49m\u001b[39muint64\u001b[39;49m\u001b[39m\"\u001b[39;49m)}),\n\u001b[1;32m   3537\u001b[0m     batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3538\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   3539\u001b[0m     remove_columns\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumn_names,\n\u001b[1;32m   3540\u001b[0m     keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   3541\u001b[0m     load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   3542\u001b[0m     cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   3543\u001b[0m     writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   3544\u001b[0m     fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   3545\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   3546\u001b[0m     suffix_template\u001b[39m=\u001b[39;49msuffix_template,\n\u001b[1;32m   3547\u001b[0m     new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   3548\u001b[0m     input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   3549\u001b[0m     desc\u001b[39m=\u001b[39;49mdesc \u001b[39mor\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mFilter\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   3550\u001b[0m )\n\u001b[1;32m   3551\u001b[0m new_dataset \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m   3552\u001b[0m new_dataset\u001b[39m.\u001b[39m_indices \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    526\u001b[0m }\n\u001b[1;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:3004\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2996\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2997\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   2998\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   2999\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3002\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3003\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3004\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3005\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3006\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:3380\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3376\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   3377\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   3378\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3380\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   3381\u001b[0m         batch,\n\u001b[1;32m   3382\u001b[0m         indices,\n\u001b[1;32m   3383\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   3384\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   3385\u001b[0m     )\n\u001b[1;32m   3386\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3387\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3389\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:3261\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3260\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3261\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3263\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3264\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3265\u001b[0m     }\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/datasets/arrow_dataset.py:6065\u001b[0m, in \u001b[0;36mget_indices_from_mask_function\u001b[0;34m(function, batched, with_indices, input_columns, indices_mapping, *args, **fn_kwargs)\u001b[0m\n\u001b[1;32m   6062\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_examples):\n\u001b[1;32m   6063\u001b[0m         example \u001b[39m=\u001b[39m {key: batch[key][i] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m batch}\n\u001b[1;32m   6064\u001b[0m         mask\u001b[39m.\u001b[39mappend(\n\u001b[0;32m-> 6065\u001b[0m             function(example, indices[i], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_kwargs) \u001b[39mif\u001b[39;00m with_indices \u001b[39melse\u001b[39;00m function(example, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   6066\u001b[0m         )\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     \u001b[39m# inputs is a list of columns\u001b[39;00m\n\u001b[1;32m   6069\u001b[0m     columns: List[List] \u001b[39m=\u001b[39m inputs\n",
      "Cell \u001b[0;32mIn[198], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m      1\u001b[0m ds[\u001b[39m'\u001b[39m\u001b[39mtest_viz\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ds[\u001b[39m'\u001b[39m\u001b[39mtest_viz\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfilter(\u001b[39mlambda\u001b[39;00m ex: ex[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem() \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m ds_test_viz \u001b[39m=\u001b[39m ds_test_viz\u001b[39m.\u001b[39mfilter(\u001b[39mlambda\u001b[39;00m ex: ex[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mitem() \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "ds['test_viz'] = ds['test_viz'].filter(lambda ex: ex['label'].item() == 4)\n",
    "ds_test_viz = ds_test_viz.filter(lambda ex: ex['label'].item() == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "670bc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels), \"f1\":f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8181cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class TwitterTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # print (\"inputs: \", inputs)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6e1cc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = TwitterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5a4c53a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "51fb930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func(inputs, position = 0):\n",
    "    \"\"\"\n",
    "        Wrapper around prediction method of pipeline\n",
    "    \"\"\"\n",
    "    pred = model(inputs, attention_mask=torch.ones_like(inputs).to(device))\n",
    "    return pred[position]\n",
    "    \n",
    "def visualize(inputs: list, attributes: list):\n",
    "    \"\"\"\n",
    "        Visualization method.\n",
    "        Takes list of inputs and correspondent attributs for them to visualize in a barplot\n",
    "    \"\"\"\n",
    "    attr_sum = attributes.sum(-1) \n",
    "    \n",
    "    attr = attr_sum / torch.norm(attr_sum)\n",
    "    \n",
    "    a = pd.Series(attr.numpy()[0], \n",
    "                        index = tokenizer.convert_ids_to_tokens(inputs.detach().numpy()[0]))\n",
    "    \n",
    "    plt.show(a.plot.barh(figsize=(10,20)))\n",
    "                    \n",
    "def explain(text: str):\n",
    "    \"\"\"\n",
    "        Main entry method. Passes text through series of transformations and through the model. \n",
    "        Calls visualization method.\n",
    "    \"\"\"\n",
    "    prediction = trainer.predict(text)\n",
    "    inputs = generate_inputs(text)\n",
    "    baseline = generate_baseline(sequence_len = inputs.shape[1])\n",
    "    \n",
    "    lig = LayerIntegratedGradients(forward_func, getattr(model, 'Twitter/twhin-bert-base').embeddings)\n",
    "    \n",
    "    attributes, delta = lig.attribute(inputs=inputs,\n",
    "                                baselines=baseline,\n",
    "                                target = model.config.label2id[prediction[0]['label']], \n",
    "                                return_convergence_delta = True)\n",
    "    \n",
    "    visualize(inputs, attributes, prediction)\n",
    "    \n",
    "def generate_inputs(text: str):\n",
    "    \"\"\"\n",
    "        Convenience method for generation of input ids as list of torch tensors\n",
    "    \"\"\"\n",
    "    return tokenizer.encode(text, truncation=True, max_length=256, return_tensors='pt').to(device)\n",
    "\n",
    "def generate_baseline(sequence_len: int):\n",
    "    \"\"\"\n",
    "        Convenience method for generation of baseline vector as list of torch tensors\n",
    "    \"\"\"        \n",
    "    return torch.tensor([tokenizer.cls_token_id] + [tokenizer.pad_token_id] * (sequence_len - 2) + [tokenizer.sep_token_id], device = device).unsqueeze(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "21f52a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 32\n",
       "})"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test_viz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0b4a17b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m factory \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(ds[\u001b[39m'\u001b[39m\u001b[39mtest_viz\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m text \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(ds_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_' is not defined"
     ]
    }
   ],
   "source": [
    "factory = iter(ds['test_viz'])\n",
    "text = iter(ds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f12279c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,  1374,  7768,  1340,  6229, 13272,   532,   959,  1119,   748,\n",
       "          3137,  1236,   538,  1284,    10, 74729, 38629,   117, 23417,  3129,\n",
       "            17, 15072,     2,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d47ad320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> @Eniledamstupid not exorbitantly but a consistent $1 per drink which i respect</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c69b3ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i would NEVER get my partners face tatted on me period. a name is already risky but their FACE?! nah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = next(factory)\n",
    "example_text = next(text)\n",
    "print(example_text['tweet_text'])\n",
    "\n",
    "prediction = trainer.predict([example])\n",
    "inputs = generate_inputs(example_text['tweet_text'])\n",
    "baseline = generate_baseline(sequence_len = inputs.shape[1])\n",
    "lig = LayerIntegratedGradients(forward_func, model.bert.embeddings)\n",
    "attributes, delta = lig.attribute(inputs=inputs,\n",
    "                            baselines=baseline,\n",
    "                            target = model.config.label2id[model.config.id2label[prediction.label_ids[0]]], \n",
    "                            return_convergence_delta = True)\n",
    "visualize(inputs, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e67948c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertForSequenceClassification' object has no attribute 'Twitter/twhin-bert-base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[39m=\u001b[39m generate_inputs(example_text[\u001b[39m'\u001b[39m\u001b[39mtweet_text\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m baseline \u001b[39m=\u001b[39m generate_baseline(sequence_len \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m lig \u001b[39m=\u001b[39m LayerIntegratedGradients(forward_func, \u001b[39mgetattr\u001b[39;49m(model, \u001b[39m'\u001b[39;49m\u001b[39mTwitter/twhin-bert-base\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39membeddings)\n\u001b[1;32m      6\u001b[0m attributes, delta \u001b[39m=\u001b[39m lig\u001b[39m.\u001b[39mattribute(inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m      7\u001b[0m                             baselines\u001b[39m=\u001b[39mbaseline,\n\u001b[1;32m      8\u001b[0m                             target \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlabel2id[model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mid2label[prediction\u001b[39m.\u001b[39mlabel_ids[\u001b[39m0\u001b[39m]]], \n\u001b[1;32m      9\u001b[0m                             return_convergence_delta \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m visualize(inputs, attributes, prediction)\n",
      "File \u001b[0;32m~/miniconda3/envs/SI699proj/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'Twitter/twhin-bert-base'"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = generate_inputs(example_text['tweet_text'])\n",
    "baseline = generate_baseline(sequence_len = inputs.shape[1])\n",
    "\n",
    "lig = LayerIntegratedGradients(forward_func, getattr(model, 'Twitter/twhin-bert-base').embeddings)\n",
    "\n",
    "attributes, delta = lig.attribute(inputs=inputs,\n",
    "                            baselines=baseline,\n",
    "                            target = model.config.label2id[model.config.id2label[prediction.label_ids[0]]], \n",
    "                            return_convergence_delta = True)\n",
    "\n",
    "visualize(inputs, attributes, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008dddc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "rec = viz.VisualizationDataRecord(attr, \n",
    "                            .9,\n",
    "                            model.config.label2id[model.config.id2label[prediction.label_ids[0]]],\n",
    "                            0,\n",
    "                            id2label[0],\n",
    "                            attributes.sum(),\n",
    "                            tokenizer.convert_ids_to_tokens(inputs.detach().numpy()[0]),\n",
    "                            delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7dd6ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "attr = attributes.sum(dim=2).squeeze(0)\n",
    "attr = attr / torch.norm(attr)\n",
    "attr = attr.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6522f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs.detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9175d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.visualize_text([rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10140a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence\n",
    "\n",
    "\n",
    "# Below we define a set of helper function for constructing references / baselines for word tokens, token types and position ids. We also provide separate helper functions that allow to construct attention masks and bert embeddings both for input and reference.\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id):\n",
    "    question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "    text_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "    # construct input token ids\n",
    "    input_ids = [cls_token_id] + question_ids + [sep_token_id] + text_ids + [sep_token_id]\n",
    "\n",
    "    # construct reference token ids \n",
    "    ref_input_ids = [cls_token_id] + [ref_token_id] * len(question_ids) + [sep_token_id] +         [ref_token_id] * len(text_ids) + [sep_token_id]\n",
    "\n",
    "    return torch.tensor([input_ids], device=device), torch.tensor([ref_input_ids], device=device), len(question_ids)\n",
    "\n",
    "def construct_input_ref_token_type_pair(input_ids, sep_ind=0):\n",
    "    seq_len = input_ids.size(1)\n",
    "    token_type_ids = torch.tensor([[0 if i <= sep_ind else 1 for i in range(seq_len)]], device=device)\n",
    "    ref_token_type_ids = torch.zeros_like(token_type_ids, device=device)# * -1\n",
    "    return token_type_ids, ref_token_type_ids\n",
    "\n",
    "def construct_input_ref_pos_id_pair(input_ids):\n",
    "    seq_length = input_ids.size(1)\n",
    "    position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n",
    "    # we could potentially also use random permutation with `torch.randperm(seq_length, device=device)`\n",
    "    ref_position_ids = torch.zeros(seq_length, dtype=torch.long, device=device)\n",
    "\n",
    "    position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    ref_position_ids = ref_position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "    return position_ids, ref_position_ids\n",
    "    \n",
    "def construct_attention_mask(input_ids):\n",
    "    return torch.ones_like(input_ids)\n",
    "\n",
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids,                                     token_type_ids=None, ref_token_type_ids=None,                                     position_ids=None, ref_position_ids=None):\n",
    "    input_embeddings = model.bert.embeddings(input_ids, token_type_ids=token_type_ids, position_ids=position_ids)\n",
    "    ref_input_embeddings = model.bert.embeddings(ref_input_ids, token_type_ids=ref_token_type_ids, position_ids=ref_position_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings\n",
    "\n",
    "\n",
    "# Let's define the `question - text` pair that we'd like to use as an input for our Bert model and interpret what the model was forcusing on when predicting an answer to the question from given input text \n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "question, text = \"What is important to us?\", \"It is important to us to include, empower and support humans of all kinds.\"\n",
    "\n",
    "\n",
    "# Let's numericalize the question, the input text and generate corresponding baselines / references for all three sub-embeddings (word, token type and position embeddings) types using our helper functions defined above.\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "input_ids, ref_input_ids, sep_id = construct_input_ref_pair(question, text, ref_token_id, sep_token_id, cls_token_id)\n",
    "token_type_ids, ref_token_type_ids = construct_input_ref_token_type_pair(input_ids, sep_id)\n",
    "position_ids, ref_position_ids = construct_input_ref_pos_id_pair(input_ids)\n",
    "attention_mask = construct_attention_mask(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "attributions_start_sum = summarize_attributions(attributions_start)\n",
    "attributions_end_sum = summarize_attributions(attributions_end)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# storing couple samples in an array for visualization purposes\n",
    "start_position_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_start_sum,\n",
    "                        torch.max(torch.softmax(start_scores[0], dim=0)),\n",
    "                        torch.argmax(start_scores),\n",
    "                        torch.argmax(start_scores),\n",
    "                        str(ground_truth_start_ind),\n",
    "                        attributions_start_sum.sum(),       \n",
    "                        all_tokens,\n",
    "                        delta_start)\n",
    "\n",
    "end_position_vis = viz.VisualizationDataRecord(\n",
    "                        attributions_end_sum,\n",
    "                        torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "                        torch.argmax(end_scores),\n",
    "                        torch.argmax(end_scores),\n",
    "                        str(ground_truth_end_ind),\n",
    "                        attributions_end_sum.sum(),       \n",
    "                        all_tokens,\n",
    "                        delta_end)\n",
    "\n",
    "print('\\033[1m', 'Visualizations For Start Position', '\\033[0m')\n",
    "viz.visualize_text([start_position_vis])\n",
    "\n",
    "print('\\033[1m', 'Visualizations For End Position', '\\033[0m')\n",
    "viz.visualize_text([end_position_vis])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
